{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process FITBIT's json heart rate files\n",
    "# Usually one activity per file, and creates a dataframe per activity\n",
    "# Heart rates with low confidence are not included in the dataframe\n",
    "# If there are no high confidence heart rates, the dataframe is not used\n",
    "\n",
    "# The process checks that there are no long periods with no activity in the dataframe\n",
    "# If there is such a period, a new activity dataframe after the silent period is created\n",
    "\n",
    "# The process also removes short activities \n",
    "\n",
    "# reset_indexing of the dataframe is used often to prevent warrnings, see:\n",
    "# http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for high/low confidence, long silent period, short time activity, peak zone\n",
    "\n",
    "confidence_limit = 0    #0 - low confidence; 1,2,3 - high enough confidence\n",
    "silent_time_limit = \"20 minutes\"\n",
    "short_time_limit = \"5 minutes\"\n",
    "peak_zone_limit=135    # My peak zone limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHeartRate(df):\n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df['dateTime']).dt.date\n",
    "    df['Time'] = pd.to_datetime(df['dateTime']).dt.time\n",
    "    \n",
    "    # Copying the dict values to the dataframe, based on:\n",
    "    # https://stackoverflow.com/questions/29681906/python-pandas-dataframe-from-series-of-dict\n",
    "    \n",
    "    temp_df = pd.DataFrame(list(df['value']))\n",
    "    df['BPM']=temp_df['bpm']\n",
    "    df['Confidence']=temp_df['confidence']\n",
    " \n",
    "    # Cleans the data frame from low confidence heart rates\n",
    "    # The if clause prevents removing all items and returning an empty df\n",
    "    # The dfExists flag indicates that there is no valid dataframe\n",
    "    # The reset_index create a new continuos index starting with zero   \n",
    "     \n",
    "    dfTemp=df[df[:]['Confidence']>confidence_limit]\n",
    "    \n",
    "    if len(dfTemp)>1:\n",
    "        dfExists=True\n",
    "        dfNew=dfTemp.reset_index(drop=True)\n",
    "    else:\n",
    "        #print('File with only low confidnece readings',df.iloc[0]['Date'],end=' ')\n",
    "        dfExists=False\n",
    "        dfNew=df\n",
    "    \n",
    "    return dfExists, dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSummery(df,fileName):\n",
    "    \n",
    "    Date=df.iloc[0]['Date'] # Assumes a single date along the dataframe\n",
    "    \n",
    "    Duration= datetime.combine( Date, df['Time'].max() ) - datetime.combine( Date,df['Time'].min() )\n",
    "    MeanBPM=round(df['BPM'].mean(),0)\n",
    "    MaxBPM=df['BPM'].max()\n",
    "    \n",
    "    peak1=df['BPM']>peak_zone_limit\n",
    "    peak2=peak1.value_counts()\n",
    "    try:\n",
    "        PeakZone=peak2[True]\n",
    "    except KeyError:\n",
    "        PeakZone=0\n",
    "        \n",
    "    String= str(df.iloc[0]['Date']) + ' ' + str(Duration) + ' ' + str(MeanBPM)   \n",
    "    Summary = {'string': String, 'date': Date, 'meanBPM': MeanBPM, 'maxBPM': MaxBPM,\\\n",
    "               'duration':Duration, 'peakZone': PeakZone, 'fileName': fileName}\n",
    "\n",
    "    return Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each json heart rate file covers a day; this function identifies days with more than one activity\n",
    "# Uses a hurisitc, that there is no data for more than 20 minutes, to divide into a new activity\n",
    "\n",
    "def identifySilentTime(df):\n",
    "    \n",
    "    breakExists=False\n",
    "    j=0\n",
    "    for i in range(len(df)-1):\n",
    "        delta=df.iloc[i+1]['dateTime'] - df.iloc[i]['dateTime']\n",
    "        if (delta>pd.Timedelta(silent_time_limit)):\n",
    "            #print('BREAK ',i,df.iloc[i]['Time'],df.iloc[i+1]['Time'])\n",
    "            breakExists=True\n",
    "            j=i\n",
    "            break\n",
    "    return breakExists,j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n"
     ]
    }
   ],
   "source": [
    "files=glob.glob(\"DATA\\heart_rate*.json\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0          # File number to start from \n",
    "end=293             # Process up to this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 293 start 0 end 293 files to read 293\n"
     ]
    }
   ],
   "source": [
    "filesToRead=files[start:end]\n",
    "print('files',len(files),'start',start,'end',end, 'files to read',len(filesToRead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process monitoring, file numbers: - standard df, / time break dfs, no df *\n",
      "0/0*1/1/1/1*2/2/2-3/3/3/3/3-4/4-5-6/6-7/7/7-8/8-9/9-10/10-11/11*12/12-13-14/14-15/15-16-17-18-19/19-20-21-22/22-23/23/23-24/24*25-26/26-27/27-28/28-29-30-31/31-32-33/33-34-35-36/36-37-38-39/39-40/40-41/41/41-42/42-43/43/43-44-45-46/46-47/47-48-49-50-51/51-52/52*53*54-55-56-57-58-59*60/60-61-62-63/63*64-65/65*66-67-68-69-70-71/71-72-73/73-74/74-75/75/75/75/75-76-77-78-79/79-80-81/81-82-83/83-84/84-85-86-87/87-88-89-90-91*92/92/92-93-94/94/94*95/95/95-96-97-98-99-100/100-101/101-102*103/103-104/104/104-105*106*107*108*109*110-111/111-112/112/112/112/112*113-114-115-116/116/116-117-118/118/118-119/119/119-120-121*122/122-123-124/124/124/124-125-126-127-128-129/129-130*131-132*133*134-135*136/136/136/136/136-137*138*139-140/140-141*142-143*144-145*146-147/147*148-149/149-150-151-152/152-153*154-155*156-157-158-159-160*161-162*163/163-164/164/164*165/165/165/165/165/165/165-166/166/166-167*168/168-169/169-170*171-172-173-174/174-175/175*176-177/177-178-179/179-180/180/180/180-181-182/182/182-183/183/183-184-185-186-187-188/188-189/189/189-190-191-192-193/193*194/194-195-196-197-198/198-199-200-201-202/202-203/203-204*205*206/206/206-207-208-209-210-211*212/212/212-213*214-215/215-216/216-217-218*219-220-221*222-223/223-224/224/224-225-226-227-228/228-229-230-231-232-233*234/234/234*235-236-237/237*238-239-240/240-241/241-242-243-244/244-245-246/246/246-247/247-248-249/249/249/249-250-251-252-253-254/254/254-255/255/255-256/256-257/257/257-258-259/259-260-261-262/262/262/262-263-264-265/265-266-267-268*269-270/270-271/271/271*272-273/273-274/274-275-276/276-277-278/278-279-280/280-281/281/281-282/282*283/283-284/284*285/285-286-287/287/287-288/288/288-289-290/290/290-291/291/291/291-292-\n",
      "len(DFs),len(Summaries) 424 424\n"
     ]
    }
   ],
   "source": [
    "DFs=[]\n",
    "Summaries=[]\n",
    "\n",
    "print('Process monitoring, file numbers: - standard df, / time break dfs, no df *')\n",
    "readNewFile=True\n",
    "i=0\n",
    "while (i< len(filesToRead)) or (not readNewFile): \n",
    "        \n",
    "    if (readNewFile):\n",
    "        fileName=filesToRead[i]\n",
    "        df0=pd.read_json(fileName)\n",
    "        i+=1 # Next file \n",
    "        \n",
    "    dfExists, df = processHeartRate(df0)\n",
    "    \n",
    "    if (dfExists):\n",
    "                \n",
    "        breakExists,breakIndex=identifySilentTime(df)\n",
    "        if (breakExists):\n",
    "            df1=df[0:breakIndex+1]\n",
    "            df0=df[breakIndex+1:].reset_index(drop=True)\n",
    "            readNewFile=False\n",
    "            print(i-1,end='/')\n",
    "        else: # (NOT breakExists)\n",
    "            df1=df\n",
    "            readNewFile=True\n",
    "            print(i-1,end='-')\n",
    "        # IF (breakExists) ends\n",
    "        \n",
    "        DFs.append(df1)\n",
    "        summary = calculateSummery(df1,fileName)\n",
    "        Summaries.append(summary)\n",
    "    \n",
    "    else: # (NOT dfExists)\n",
    "        print(i-1,end='*')\n",
    "        readNewFile=True\n",
    "    # IF (dfExists) ends\n",
    "    \n",
    "# WHILE ends \n",
    "print('\\nlen(DFs),len(Summaries)',len(DFs),len(Summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 9 11 15 19 23 25 30 37 42 43 45 56 59 62 67 99 113 114 125 139 144 154 155 156 162 163 172 175 179 181 192 193 194 196 197 199 201 207 214 215 221 230 239 243 247 250 251 252 256 261 268 273 281 288 293 298 300 303 304 312 322 327 331 346 348 354 \n",
      " Summaries 357\n",
      "2 9 11 15 19 23 25 30 37 42 43 45 56 59 62 67 99 113 114 125 139 144 154 155 156 162 163 172 175 179 181 192 193 194 196 197 199 201 207 214 215 221 230 239 243 247 250 251 252 256 261 268 273 281 288 293 298 300 303 304 312 322 327 331 346 348 354 \n",
      " DFs 357\n"
     ]
    }
   ],
   "source": [
    "# Remove short sequences\n",
    "\n",
    "for idx, d in enumerate(Summaries):\n",
    "    delta=d['duration']\n",
    "    if (delta<pd.Timedelta(short_time_limit)):\n",
    "        print(idx,end=' ')\n",
    "        del Summaries[idx]\n",
    "print('\\n Summaries',len(Summaries))\n",
    "\n",
    "for idx, df in enumerate(DFs):\n",
    "    Date=df.iloc[0]['Date']\n",
    "    delta=datetime.combine( Date, df['Time'].max() ) - datetime.combine( Date,df['Time'].min() )\n",
    "    if (delta<pd.Timedelta(short_time_limit)):\n",
    "        print(idx,end=' ')\n",
    "        del DFs[idx]\n",
    "print('\\n DFs',len(DFs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(DFs, open('DFs.pkl', 'wb'))\n",
    "pickle.dump(Summaries, open('Summaries.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
